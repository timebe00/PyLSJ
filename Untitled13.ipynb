{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 5 3 2 2 0 9]\n",
      " [3 7 5 6 6 7 6]\n",
      " [7 8 4 7 8 9 9]\n",
      " [0 4 4 6 5 9 1]\n",
      " [1 9 4 1 6 5 1]\n",
      " [6 2 8 6 6 4 6]\n",
      " [5 4 9 4 1 9 3]]\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 10, (7, 7))\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_np = np.ones([7, 7])\n",
    "\n",
    "print(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([-1,0,1])\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(kernel))\n",
    "print(type(img_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# cv2.resize : cv2라는 라이브러리를 쓰기 위해서 변환해준다.\n",
    "img_cv = cv2.resize(img_np, (7, 7))\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.resize(kernel,(1,3))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img_cv))\n",
    "print(type(kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 2. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv[0][0] = 0\n",
    "img_cv[3][3] = 2\n",
    "img_cv[6][6] = 3\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# filter2D - Convolution이\n",
    "# 결국 라플라스 변환과 푸리에 변환에 관계를 가지고 있기 때문\n",
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라플라스 변환 => 전달함술르 얻기 위해 계산함\n",
    "# 입력대 출력비를 구하겠다.\n",
    "# 입력이 10, 출력이 7, 입력비:7/10\n",
    "# 입력이 y'' = y'+3y+2\n",
    "# 출력이 y' = 3e^3x\n",
    "# 라플라스 변환 통해 입출력비를 계산할 수 있게 된다.\n",
    "\n",
    "# Low Pass Filter(LPF 설계법) - 1D Convolution\n",
    "# 전달한수 -> 실제 값을 필터링 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(\n",
    "    Conv2D(\n",
    "        32, (3, 3),\n",
    "        input_shape = (64, 64, 3),\n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7200)              0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(128, activationif str(layer) != last_layer:='relu'))\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(1, activation= 'sigmoid'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainSet = train_gen.flow_from_directory(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/' +\n",
    "    'Datasets/dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "testSet = test_gen.flow_from_directory(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/' +\n",
    "    'Datasets/dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.6929 - accuracy: 0.5194 - val_loss: 0.6689 - val_accuracy: 0.6075\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.6642 - accuracy: 0.6044 - val_loss: 0.6314 - val_accuracy: 0.6237\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.6116 - accuracy: 0.6616 - val_loss: 0.5783 - val_accuracy: 0.7100\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5976 - accuracy: 0.6800 - val_loss: 0.5723 - val_accuracy: 0.6888\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.5727 - accuracy: 0.7072 - val_loss: 0.6255 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5698 - accuracy: 0.6906 - val_loss: 0.5555 - val_accuracy: 0.7100\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5580 - accuracy: 0.7156 - val_loss: 0.5407 - val_accuracy: 0.7200\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.5453 - accuracy: 0.7169 - val_loss: 0.5672 - val_accuracy: 0.7138\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5503 - accuracy: 0.7169 - val_loss: 0.4953 - val_accuracy: 0.7412\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5391 - accuracy: 0.7275 - val_loss: 0.5777 - val_accuracy: 0.7075\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5416 - accuracy: 0.7159 - val_loss: 0.6531 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5387 - accuracy: 0.7200 - val_loss: 0.5551 - val_accuracy: 0.7287\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5230 - accuracy: 0.7316 - val_loss: 0.5285 - val_accuracy: 0.7312\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5341 - accuracy: 0.7347 - val_loss: 0.5284 - val_accuracy: 0.7362\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5325 - accuracy: 0.7209 - val_loss: 0.5138 - val_accuracy: 0.7425\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5199 - accuracy: 0.7450 - val_loss: 0.5282 - val_accuracy: 0.7362\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5321 - accuracy: 0.7259 - val_loss: 0.6044 - val_accuracy: 0.6888\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5348 - accuracy: 0.7309 - val_loss: 0.5210 - val_accuracy: 0.7437\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.4998 - accuracy: 0.7550 - val_loss: 0.5137 - val_accuracy: 0.7412\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.4921 - accuracy: 0.7647 - val_loss: 0.5196 - val_accuracy: 0.7713\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5084 - accuracy: 0.7494 - val_loss: 0.5066 - val_accuracy: 0.7538\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4947 - accuracy: 0.7603 - val_loss: 0.5060 - val_accuracy: 0.7650\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4920 - accuracy: 0.7644 - val_loss: 0.5340 - val_accuracy: 0.7163\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4946 - accuracy: 0.7588 - val_loss: 0.5543 - val_accuracy: 0.7250\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.4921 - accuracy: 0.7491 - val_loss: 0.5374 - val_accuracy: 0.7625\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.5004 - accuracy: 0.7569 - val_loss: 0.4737 - val_accuracy: 0.7688\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5062 - accuracy: 0.7541 - val_loss: 0.5168 - val_accuracy: 0.7275\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4812 - accuracy: 0.7628 - val_loss: 0.4828 - val_accuracy: 0.7513\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.4807 - accuracy: 0.7713 - val_loss: 0.5192 - val_accuracy: 0.7275\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.4699 - accuracy: 0.7791 - val_loss: 0.5291 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcb8c173210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "classifier.fit_generator(\n",
    "    trainSet,\n",
    "    steps_per_epoch = int(10000/batch_size),\n",
    "    epochs = 30,\n",
    "    validation_data = testSet,\n",
    "    validation_steps = int(2500/batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.load_img(\n",
    "    'test_image_2.jpg',\n",
    "    target_size = (64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(new_image)\n",
    "#trainSet.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
